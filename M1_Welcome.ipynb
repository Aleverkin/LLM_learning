{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2da22ebe-7cbc-4612-99ca-d9f0a6586026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe71b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "course_api_key = os.environ['LLM_STEPIK_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeeb0c9",
   "metadata": {},
   "source": [
    "# SIMPLE Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63f37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import NDTOpenAI\n",
    "\n",
    "client = NDTOpenAI(\n",
    "    api_key=course_api_key,  # ключ для доступа к апи\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa07f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI(\n",
    "#     # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
    "#     api_key=openai_api_key,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12809ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='2', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",  # Роль - ассистент или юзер\n",
    "        \"content\": \"1+1\",  # Сам промпт для подачи в chatGPT\n",
    "    }\n",
    "]\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    max_tokens=100,\n",
    "    model=\"gpt-3.5-turbo\",  # модель для выбора\n",
    "    messages=messages,  # сообщение\n",
    "    temperature=0,  # степень креативности ответа\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a94fa",
   "metadata": {},
   "source": [
    "# Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a386eb-72bc-4e4e-a85d-f202c92f4416",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Когда человек первый раз полетел в космос?', 'text': '12 апреля 1961 года.'}\n"
     ]
    }
   ],
   "source": [
    "#from langchain_openai import ChatOpenAI # <-- класс из LangChain\n",
    "from utils import ChatOpenAI  # <-- наш класс!\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Вопрос: {question}\n",
    "Ответ: Дай короткий ответ\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "openai_llm = ChatOpenAI(temperature=0.0, course_api_key=course_api_key)\n",
    "#openai_llm = ChatOpenAI(temperature=0.0, openai_api_key=openai_api_key)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=openai_llm)\n",
    "\n",
    "question = \"Когда человек первый раз полетел в космос?\"\n",
    "\n",
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccd2c55-75b2-4a6a-9b8d-be845d20fd3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dd7d6b0-0d57-474d-8fed-9b2c7acc1e85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0dd5e4-de74-4346-9bb6-0a73981d92fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Artem\\.conda\\envs\\llm_stepik\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\Artem\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import HuggingFaceEndpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# initialize HF LLM\n",
    "hf_llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\", # вводим название модели с HuggingFace\n",
    "    #repo_id=\"google/flan-t5-base\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "025a8a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Artem\\.conda\\envs\\llm_stepik\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The first human to fly into space was Yuri Gagarin from the Soviet Union. He orbited the Earth once on April 12, 1961, aboard Vostok 1. This event marked the beginning of human spaceflight. Gagarin's spacecraft landed safely and he became an international hero. The United States' Alan Shepard became the first American in space, but he only reached suborbital space and did not orbit the Earth.\n"
     ]
    }
   ],
   "source": [
    "# build prompt template for simple question-answering\n",
    "template = \"\"\"Question: {question}.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=hf_llm)\n",
    "\n",
    "question = \"When did man first fly into space?\"\n",
    "\n",
    "print(llm_chain.invoke(question)['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f974a89-3e5f-456f-9710-9a47101d2d80",
   "metadata": {},
   "source": [
    "# BY LOCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aae273b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "020451fb-af1c-4256-91d9-04f4e384d8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "bloom = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"bigscience/bloom-1b7\",  # Название и версия модели, позже покажем вам весь LLM-зоопарк\n",
    "    task=\"text-generation\",  # Вид задачи, в нашем случае - генерация текста\n",
    "    model_kwargs={\n",
    "        \"temperature\": 0,\n",
    "        \"max_length\": 64,\n",
    "    },  # все те же креативность и максимальная длина\n",
    "    device=0,  # Номер GPU карточки, если есть!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68b323b-f6ed-4ef7-b33d-6c2c287278fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who the most popular porn actress?.\n",
      "\n",
      "Answer: The most popular porn actress is the one who has the most viewers.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"Question: {question}.\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=bloom)\n",
    "\n",
    "question = \"Who the most popular porn actress?\"\n",
    "\n",
    "print(llm_chain.invoke(question)['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_stepik",
   "language": "python",
   "name": "llm_stepik"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
